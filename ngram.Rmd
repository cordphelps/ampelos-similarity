---
title: "ngram
---




```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, results='hide')

# https://yihui.org/knitr/options/

# echo: (TRUE; logical or numeric) Whether to display the source code
# results: ('markup'; character) Controls how to display the text results.
# warning: (TRUE; logical) Whether to preserve warnings
# error: (TRUE; logical) Whether to preserve errors
# include: (TRUE; logical) Whether to include the chunk output in the output document.
# 
```

```{r localCode, echo=FALSE, include=FALSE}

  output.path <- "/Users/rcphelps/code/groq/output"
  setwd("/Users/rcphelps/code/groq")
    
# install.packages("tinytex")
library(tinytex)
library(tidyverse)
library(dplyr)



```



```{r evaluateNGRAMs, echo=FALSE, include=F, results='asis', message=F, warning=F}

# ================================================================================
#
# for 3 week clusters, across 2 transects, plot the am/pm posterior distributions 
# and the distribution credible intervals to assess 'similarity'
#
#
# ================================================================================

source.row.url <- c("./metrics/NGRAM_row.csv")
# written by the python function spider_lib.julian_row_compare_alternate(week_records_df)
#  transect julian time week row_a_text row_b_text row_c_text row1_row2 row1_row3 row2_row3
#0  control    236   pm   34  f f f f f f f f f f   f f f f f f f f T f   f f f f f f f f f T   0.703704  0.703704  0.703704

source.transect.url <- c("./metrics/NGRAM_transect.csv")


  # ------------------------------------------------------------------------
  plotHistBox <- function(tr, time, long.df, short.df, chart.text) {
    
    if (chart.text == 'opposing') {
      box.position = 55
    } else {
      box.position = 55
    }
    
    NGRAM.median <- median(short.df$value)
    NGRAM.not.equal.one.variance <- var(subset(short.df, !(value %in% c(1)))$value)
    # (also)
    # NGRAM.not.equal.one.variance <- var(not.one.tibl$value)
    
    #print(paste("NGRAM.not.equal.one median= ", NGRAM.median, " mean: ", mean(short.df$value), sep=""))
    #print(paste("    NGRAM.not.equal.one variance= ", NGRAM.not.equal.one.variance, sep=""))
    
    NGRAM.median <- round(NGRAM.median, digits = 2)
    NGRAM.variance <- round(NGRAM.not.equal.one.variance, digits = 2)
    
    NGRAM.mean <- mean(short.df$value)
    NGRAM.mean <- round(NGRAM.mean, digits = 2)
    
    stats.df <- short.df %>%
      summarize(
        ymin = round(min(value[value >= quantile(value, 0.25) - 1.5 * IQR(value)]), digits=2),
        lower = round(quantile(value, 0.25), digits=2),
        middle = round(median(value), digits=2),
        upper = round(quantile(value, 0.75), digits=2),
        ymax = round(max(value[value <= quantile(value, 0.75) + 1.5 * IQR(value)]), digits=2)
      )
    
    IQR.lower <- round(stats.df$lower, digits=3)
  
    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2")
    # https://sape.inf.usi.ch/quick-reference/ggplot2/colour
    
    gg.dist <- ggplot() +
      
      # color="#FF00FF",
    geom_histogram(data=long.df, aes(x=value),  binwidth = 0.01 ) + 
    
      # , size=2, fill="green4", color="limegreen"
    geom_boxplot(data=short.df, aes(x = value, y = box.position), width=2.5) +
    
    scale_x_continuous(limits=c(0, 1.1), breaks=seq(0, 1.1, 0.1) ) +
    
    theme_bw() +
    
    labs(y = "row pairs assessed (count)", 
         x = paste("NGRAM computed value\n", chart.text, " transect, same day row-to-row comparison\n(boxplot excludes NGRAM=1)",sep=""),
         caption = paste("daily rows presence pattern compared\n", 
                         "transect: ", tr, " daytime: ", daytime, 
                         "\nboxplot median: ", NGRAM.median,
                         "\nboxplot IQR lower: ", IQR.lower,
                         "\nboxplot mean: ", NGRAM.mean, sep="" ))
    
    print(gg.dist)
    
    setwd("/Users/rcphelps/code/groq/")
    saveGGpng(filename = paste("ngram.dist.", tr, ".", daytime, ".png", sep=""), 
            subdir = "png.output", gg = gg.dist)
    
    return(stats.df)
  }
# ------------------------------------------------------------------------


library(dplyr)

NGRAM.row.tibl <- dplyr::as_tibble(read.csv(source.row.url, header=TRUE, row.names=NULL))

# squeeze the width to make the png fit
tb <- as.tibble(NGRAM.row.tibl)
tb$row1_row2 <- round(as.double(tb$row1_row2), digits=3)
tb$row1_row3 <- round(as.double(tb$row1_row3), digits=3)
tb$row2_row3 <- round(as.double(tb$row2_row3), digits=3)
tb <- tb %>% rename(r1r2 = row1_row2)
tb <- tb %>% rename(r1r3 = row1_row3)
tb <- tb %>% rename(r2r3 = row2_row3)
tb$transect[tb$transect == "oakMargin"] <- "SNH"
saveDFpng(filename = "ngram.row.png", subdir = "png.output", df= head(tb))
  
library(coda)

NGRAM.row.tibl <- NGRAM.row.tibl %>%
  filter(week %in% c('23', '24', '25', '26', '27', '28', '29', '30', '31'))

for (xsect in list("oakMargin", "control")) {
  
  for (daytime in list("am", "pm")) {
  
    t.tibl <- NGRAM.row.tibl %>% 
      dplyr::filter(transect == xsect) %>% 
      dplyr::filter(time == daytime) 
    
    library(tidyr)
    
    stacked.tibl <- pivot_longer(
      t.tibl,
      cols = c(row1_row2, row1_row3, row2_row3),
      names_to = "column",
      values_to = "value"
      )
    
    stacked.tibl$value <- as.numeric(stacked.tibl$value)
    
    not.one.tibl <- stacked.tibl %>%
      dplyr::filter(value != 1)
      
    
    t.NGRAM <- length(stacked.tibl$value)
    NGRAM.not.equal.one <- length(subset(stacked.tibl, !(value %in% c(1)))$value)
    values.equal.one <- t.NGRAM - NGRAM.not.equal.one
    
    #print(paste("total count= ", t.NGRAM, sep=""))
    #print(paste("values.not.equal.one= ", values.not.equal.one, sep=""))
    
    stats.df <- plotHistBox(tr = xsect, time = daytime, long.df = stacked.tibl, short.df = not.one.tibl, chart.text="same")
    
    print(paste("stats: ", stats.df, "\n", sep=""))
    
    }
  
  
  }
  

  
  
  # ===========================================================================================
  # ===========================================================================================
  # ===========================================================================================
  NGRAM.transect.tibl <- dplyr::as_tibble(read.csv(source.transect.url, header=TRUE, row.names=NULL))
  

library(coda)

NGRAM.transect.tibl <- NGRAM.transect.tibl %>%
  filter(week %in% c('23', '24', '25', '26', '27', '28', '29', '30', '31'))
  
for (daytime in list("am", "pm")) {
    
    t.tibl <- NGRAM.transect.tibl %>% 
      dplyr::filter(time == daytime) 
    
  library(tidyr)
    
  stacked.transect.tibl <- pivot_longer(
      t.tibl,
      cols = c(ng1, ng2, ng3, ng4, ng5, ng6, ng7, ng8, ng9),
      names_to = "column",
      values_to = "value"
      )
  
  stacked.transect.tibl$value <- as.numeric(stacked.transect.tibl$value)
  
      not.one.transect.tibl <- stacked.transect.tibl %>%
      dplyr::filter(value != 1)
      
    t.NGRAM <- length(stacked.transect.tibl$value)
    values.not.equal.one <- length(subset(stacked.transect.tibl, !(value %in% c(1)))$value)
    values.equal.one <- t.NGRAM - NGRAM.not.equal.one
    
    #print(paste("total tr count= ", t.NGRAM, sep=""))
    #print(paste("tr values.not.equal.one= ", values.not.equal.one, sep=""))
    
    stats.df <- plotHistBox(tr = 'SNH-vs-control', time = daytime, long.df = stacked.transect.tibl, short.df = not.one.transect.tibl, chart.text="opposing")
    
    #print(paste("stats: ", stats.df, "\n", sep=""))

}

```

```{r mw-u-test, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}

library(dplyr)
library(tidyr)
library(tibble)

wilcox.test.tibl <- tibble(
  time = character(),
  week = character(),
  row.days = integer(),
  U = double(),
  p.value = double()
)


nonZero.counts.url <- c('./metrics/binomial_nonZero_counts_row.csv')

nonZero.tibl <- dplyr::as_tibble(read.csv(nonZero.counts.url, header=TRUE, row.names=NULL))
nonZero.tibl$week <- as.character(nonZero.tibl$week) 
  
core.weeks = c('23', '24', '25', '26', '27', '28', '29', '30', '31')
# core.weeks = c('32', '33', '34')
# Error in wilcox.test.default(oakMargin.tibl$nonZero, y = control.tibl$nonZero,  : 
# not enough (non-missing) 'x' observations
nonZero.tibl <- nonZero.tibl %>%
  filter(week %in% core.weeks)

  
  for (daytime in list("am", "pm")) {
    
    for (wk in core.weeks) {
  
      t.tibl <- nonZero.tibl %>% 
        dplyr::filter(time == daytime) %>%
        dplyr::filter(week == wk) 
        
        oakMargin.tibl <- t.tibl %>% 
          dplyr::filter(transect == 'oakMargin') 
        
        control.tibl <- t.tibl %>% 
          dplyr::filter(transect == 'control') 
    
        # "two.sided" = detect any difference (positive or negative) between groups
        stats.df <- stats::wilcox.test(oakMargin.tibl$nonZero, y = control.tibl$nonZero,
                alternative = "two.sided",
                mu = 0, paired = FALSE, exact = NULL, correct = TRUE,
                conf.int = FALSE, conf.level = 0.95,
                tol.root = 1e-4, digits.rank = Inf)
        
        # in R, when you use `wilcox.test()`, the reported statistic is the Mann-Whitney U
        # statistic, which is a linear transformation of the rank sum statistic (W). 
        print(paste(" daytime: ", daytime, " week: ", wk, " row-days: ", nrow(control.tibl),
                    " U-statistic: ", round(stats.df$statistic, digits=2), " ",  
                    " p-value: ", round(stats.df$p.value, digits=3), 
                    sep=""))
        
        wilcox.test.tibl <- wilcox.test.tibl %>% 
          add_row(time = daytime, 
                  week = wk, 
                  row.days = nrow(control.tibl), 
                  U = round(stats.df$statistic, digits=2), 
                  p.value = round(stats.df$p.value, digits=3))
        
        # examine the odd day counts
        #if (nrow(control.tibl) < 9 ) {
          #print(oakMargin.tibl)
          #print(control.tibl)
        #}
        
      }
    }

setwd("/Users/rcphelps/code/groq/")
filename <- c('./metrics/wilcox.p.values.csv')
readr::write_csv(wilcox.test.tibl, filename)


    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2")
    # https://sape.inf.usi.ch/quick-reference/ggplot2/colour
    
    gg.wilcox <- ggplot() +
      
      # , size=2, fill="green4", color="limegreen"
    geom_boxplot(data=wilcox.test.tibl, aes(x = p.value, y = time), width=1.5) +
    
    scale_x_continuous(limits=c(0, 1.1), breaks=seq(0, 1.1, 0.1) ) +
    
    theme_bw() +
    
    labs(y = "daytime", 
         x = paste("wilcox.test() p-value",
                   sep=""),
         caption = paste("SNH vs control", 
                         "\ndistribution of daily row counts compared by week",
                          "\nweeks 23-31", 
                         "\n(Wilcoxon rank sum test (equivalent to the Mann-Whitney U test))",
                         sep="" ))
    
    print(gg.wilcox)
    
    setwd("/Users/rcphelps/code/groq/")
    saveGGpng(filename="wilcox.pdf", subdir="png.output", gg=gg.wilcox)


```

```{r evaluatePosterior, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}

# ================================================================================
#
# for 3 week clusters, across 2 transects, plot the am/pm posterior distributions 
# and the distribution credible intervals to assess 'similarity'
#
#
# ================================================================================

source.url <- c("./metrics/binomial-posterior-.csv")
# written by the python function binomial_credible_interval(df, graphics, csv_ID)

#    library(bayestestR)
# Example posterior draws from a normal distribution
#    posterior <- rnorm(1000, mean = 5, sd = 3)
# Calculate the 95% HDI (credible interval)
#    hdi_interval <- hdi(posterior, credMass = 0.95)
# Print the result
#    print(hdi_interval)

# `geom_density()` estimates the probability density function (PDF) of a continuous variable, using kernel density estimation (KDE)
# Y-Axis: Density, Not Frequency
# The y-axis shows density (not direct counts or probability).
# The area under the entire curve sums to 1.
# The height at any given x-value represents the relative likelihood of finding a data point near that value.
# Peaks in the density curve indicate values where observations are more concentrated.

# finding the credible interval
# For MCMC or simulation outputs, use the `coda` package for highest posterior density (HPD) intervals: hpd_interval <- HPDinterval(as.mcmc(samples), prob=0.95)
# Key Considerations: use HPD for skewed/multi-modal posteriors

# bayestestR
# Overlap Coefficient Measures the proportion of shared density between distributions (0 = no overlap, 1 = identical).
# Overlap < 0.05: Strong divergence
# Overlap > 0.35: Substantial similarity
# overlap_score <- overlap(posterior_A, posterior_B)


posterior.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

column_list <- names(posterior.tibl)

    # column_list[1] is 'X' corresponding to the df index
    #for (i in 2:length(column_list)) {
    #  print( paste("i: ", i, " label: ", column_list[i], sep=""))
    #}
    # [1] "i: 2 label: oakMargin.pm.week.cluster.1"
    # [[1] "i: 3 label: oakMargin.pm.week.cluster.2"
    # [[1] "i: 4 label: oakMargin.pm.week.cluster.3"
    # [[1] "i: 5 label: oakMargin.am.week.cluster.1"
    # [[1] "i: 6 label: oakMargin.am.week.cluster.2"
    # [[1] "i: 7 label: oakMargin.am.week.cluster.3"
    # [[1] "i: 8 label: control.pm.week.cluster.1"
    # [[1] "i: 9 label: control.pm.week.cluster.2"
    # [[1] "i: 10 label: control.pm.week.cluster.3"
    # [[1] "i: 11 label: control.am.week.cluster.1"
    # [[1] "i: 12 label: control.am.week.cluster.2"
    # [[1] "i: 13 label: control.am.week.cluster.3"


for (daytime in list("am", "pm")) {

    if (daytime == 'am') {
      
      dist1 = posterior.tibl$oakMargin.am.week.cluster.1
      dist1.stats <- coda::HPDinterval(as.mcmc(dist1), prob=0.95)
      #print(dist1.stats[1] ) # lower credible interval
      #print(dist1.stats[2] ) # upper credible interval
      #print(dist1.stats)
      dist2 = posterior.tibl$oakMargin.am.week.cluster.2
      dist2.stats <- coda::HPDinterval(as.mcmc(dist2), prob=0.95)
      #
      dist3 = posterior.tibl$oakMargin.am.week.cluster.3
      dist3.stats <- coda::HPDinterval(as.mcmc(dist3), prob=0.95)
      #
      dist4 = posterior.tibl$control.am.week.cluster.1
      dist4.stats <- coda::HPDinterval(as.mcmc(dist4), prob=0.95)
      #
      dist5 = posterior.tibl$control.am.week.cluster.2
      dist5.stats <- coda::HPDinterval(as.mcmc(dist5), prob=0.95)
      #
      dist6 = posterior.tibl$control.am.week.cluster.3
      dist6.stats <- coda::HPDinterval(as.mcmc(dist6), prob=0.95)
      
    } else {
      
      dist1 = posterior.tibl$oakMargin.pm.week.cluster.1
      dist1.stats <- coda::HPDinterval(as.mcmc(dist1), prob=0.95)
      #
      dist2 = posterior.tibl$oakMargin.pm.week.cluster.2
      dist2.stats <- coda::HPDinterval(as.mcmc(dist2), prob=0.95)
      #
      dist3 = posterior.tibl$oakMargin.pm.week.cluster.3
      dist3.stats <- coda::HPDinterval(as.mcmc(dist3), prob=0.95)
      #
      dist4 = posterior.tibl$control.pm.week.cluster.1
      dist4.stats <- coda::HPDinterval(as.mcmc(dist4), prob=0.95)
      #
      dist5 = posterior.tibl$control.pm.week.cluster.2
      dist5.stats <- coda::HPDinterval(as.mcmc(dist5), prob=0.95)
      #
      dist6 = posterior.tibl$control.pm.week.cluster.3
      dist6.stats <- coda::HPDinterval(as.mcmc(dist6), prob=0.95)
        
    }
    
    library(coda)
    library(bayestestR)
    
      #print( paste("overlap: ", bayestestR::overlap(dist1, dist4), sep="") )
      #print( paste("overlap: ", bayestestR::overlap(dist2, dist5), sep="") )
      #print( paste("overlap: ", bayestestR::overlap(dist3, dist6), sep="") )
    
    
    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2")
    # https://sape.inf.usi.ch/quick-reference/ggplot2/colour
    
    gg.dist <- ggplot(posterior.tibl) +
      
      geom_density(aes(x = dist1), fill = color_list[1], alpha = 0.6) +
      
      geom_density(aes(x = dist2), fill = color_list[2], alpha = 0.6) +
      
      geom_density(aes(x = dist3), fill = color_list[3], alpha = 0.6) +
      
      geom_density(aes(x = dist4), fill = color_list[4], alpha = 0.6) +
      
      geom_density(aes(x = dist5), fill = color_list[5], alpha = 0.6) +
      
      geom_density(aes(x = dist6), fill = color_list[6], alpha = 0.6) +
      
      theme_bw() +
      
      labs(x = "spider presence probability for the simulated posterior", 
           y = "relative liklihood",
           caption = paste("SNH / control pairs for 3 clusters of weeks\n",
                           "cluster 1: weeks 23-25 (dark)\n",
                           "cluster 2: weeks 26-31 (light)\n",
                           "cluster 3: weeks 32-34 (lightest)\n",
                           "daytime: ", daytime, sep="" ))
    
    print(gg.dist)
    
    setwd("/Users/rcphelps/code/groq/")
    saveGGpng(filename = paste("posterior.dist.", daytime, ".png", sep=""), 
            subdir = "png.output", gg = gg.dist)
    
    
    
    jitter_pos <- position_jitter(width=0, height = 0.2, seed = 89)
    
    gg.ci <- ggplot() +
    
      geom_pointrange(aes(y = factor('week cluster 1'),
                            # factor(column_list[9]), 
                          x = mean(dist1, na.rm = TRUE), 
                          xmin = dist1.stats[1], 
                          xmax = dist1.stats[2]), 
                      position = jitter_pos, size = 1.2,
                      color = color_list[1]) +
    
      geom_pointrange(aes(y = factor('week cluster 1'),
                               # factor(column_list[3]
                          x = mean(dist4, na.rm = TRUE),
                          xmin = dist4.stats[1], 
                          xmax = dist4.stats[2]),
                      size = 1.2,
                      color = color_list[4]
                      ) +
    
      geom_pointrange(aes(y = factor('week cluster 2'),
                            # factor(column_list[9]), 
                          x = mean(dist2, na.rm = TRUE), 
                          xmin = dist2.stats[1], 
                          xmax = dist2.stats[2]), 
                      position = jitter_pos, size = 1.2,
                      color = color_list[2]) +
    
      geom_pointrange(aes(y = factor('week cluster 2'),
                               # factor(column_list[3]
                          x = mean(dist5, na.rm = TRUE),
                          xmin = dist5.stats[1], 
                          xmax = dist5.stats[2]),
                      size = 1.2,
                      color = color_list[5]
                      ) +
    
      geom_pointrange(aes(y = factor('week cluster 3'),
                            # factor(column_list[9]), 
                          x = mean(dist3, na.rm = TRUE), 
                          xmin = dist3.stats[1], 
                          xmax = dist3.stats[2]), 
                      position = jitter_pos, size = 1.2,
                      color = color_list[3]) +
    
      geom_pointrange(aes(y = factor('week cluster 3'),
                               # factor(column_list[3]
                          x = mean(dist6, na.rm = TRUE),
                          xmin = dist6.stats[1], 
                          xmax = dist6.stats[2]),
                      size = 1.2,
                      color = color_list[6]
                      ) +
        
      theme_bw() +
    
      labs( 
            y="SNH / control pair", 
            x="spider presence probability for the simulated posterior", 
            caption = paste("posterior median and 95% credible interval\n", 
                            "daytime: ", daytime, sep="" ) 
            ) 
      
      
      print(gg.ci)
      
      setwd("/Users/rcphelps/code/groq/")
      saveGGpng(filename = paste("posterior.credible.interval.", daytime, ".pdf", sep=""), 
            subdir = "png.output", gg = gg.ci)
    
}


```


```{r makeVariance, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}

# ==============================================================================
#
# for each transect/daytime pair, plot the mean vs. the variance
# for each weekly cluster and position cluster
#
# the output graphics help to identify any overdispersion issues
# that would prevent selecting a binomial generative model for building
# sample posterior distributions
#
# ==============================================================================

# data produced by the python function
#     spider_lib.analyze_position_time_clusters(df=week_records_df)
source.url <- c("./metrics/cluster-probability-variance.csv")

# # A tibble: 36 × 7
#   transect  time  data_label trials count  mean variance
#   <chr>     <chr> <chr>       <int> <int> <dbl>    <dbl>
# 1 oakMargin am    -w1-p1-        96    25 0.260    0.255
# 2 oakMargin pm    -w1-p1-       108    48 0.444    0.617
# 3 control   am    -w1-p1-        96    24 0.25     0.229
# 4 control   pm    -w1-p1-       108    45 0.417    0.632
 
 

# It is critical that we don’t confuse the standard deviation and the standard error. The standard deviation is a property of the population. It tells us how much spread there is among individual observations we could make. By contrast, the standard error tells us how precisely we have determined a parameter estimate.
# The standard error is approximately given by the sample standard deviation divided by the square root of the sample size, and confidence intervals are calculated by multiplying the standard error with small, constant values.
#The correct way to assess whether there are differences in mean rating is to calculate confidence intervals for the differences. If those confidence intervals exclude zero, then we know the difference is significant at the respective confidence level. 
# Frequentists assess uncertainty with confidence intervals, whereas Bayesians calculate posterior distributions and credible intervals. 
# The Bayesian posterior distribution tells us how likely specific parameter estimates are given the input data. The credible interval indicates a range of values in which the parameter value is expected with a given probability, as calculated from the posterior distribution. For example, a 95% credible interval corresponds to the center 95% of the posterior distribution. The true parameter value has a 95% chance of lying in the 95% credible interval.
# To summarize, a Bayesian credible interval makes a statement about the true parameter value and a frequentist confidence interval makes a statement about the null hypothesis. 
# The central goal of Bayesian estimation is to obtain the posterior distribution. Therefore, Bayesians commonly visualize the entire distribution rather than simplifying it into a credible interval.
#
# Figures with integrated titles, subtitles, and data source statements are appropriate, however, if they are meant to be used as stand-alone infographics or to be posted on social media or on a web page without accompanying caption text.
#
# https://clauswilke.com/dataviz/visualizing-uncertainty.html 
#
#


# ==================================================================================

plotVariance <- function(df1, df2, t) {

  oak.tibl <- df1
  control.tibl <- df2
  time <- t
  
      
    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2")
    # https://sape.inf.usi.ch/quick-reference/ggplot2/colour
	
  gg <- ggplot() +
  
    geom_jitter(data=oak.tibl, 
                aes(y = mean, x = variance, group="SNH"),
                color = "mediumvioletred", fill = color_list[3], shape = 21, size=5) +
  
    geom_jitter(data=control.tibl, 
                aes(y = mean, x = variance, group="control"), 
                color = "mediumvioletred", fill = color_list[6], shape = 21, size=5) +

    geom_segment(aes(x=0, y=0, xend=0.9, yend=0.9)) +
  
    scale_colour_manual(name="transect", guide = 'legend', values = c("SNH"= color_list[3] , "control"= color_list[6] )) +
  
    scale_y_continuous(limits=c(0, 0.9), breaks=seq(0, 0.9, 0.1) ) +
    scale_x_continuous(limits=c(0, 0.9), breaks=seq(0, 0.9, 0.1) ) +
  
    theme_bw() +
    theme(legend.position="right") +

    # turn off legend
    # theme(legend.position="none") 

    labs( caption = paste("binomial probability of spiders occurring in a sample",
                        " by vine position and week cluster: daytime= ", 
                        time, "\nchecking for overdispersion; the diagonal line describes mean=variance", "\ntransect SNH is dark purple, control is light purple", sep="")
          ) 
  
    return(gg)

}

# ==================================================================================


variance.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

print(variance.tibl)

v.am.tibl <- variance.tibl %>% 
  dplyr::filter(time == 'am') 
  
oak.am.tibl <- v.am.tibl %>% 
  dplyr::filter(transect == 'oakMargin') 

control.am.tibl <- v.am.tibl %>% 
  dplyr::filter(transect == 'control') 

gg0 <- plotVariance(oak.am.tibl, control.am.tibl, t='am')

print(gg0)

v.pm.tibl <- variance.tibl %>% 
  dplyr::filter(time == 'pm') 
  
oak.pm.tibl <- v.pm.tibl %>% 
  dplyr::filter(transect == 'oakMargin') 

control.pm.tibl <- v.pm.tibl %>% 
  dplyr::filter(transect == 'control') 

gg1 <- plotVariance(oak.pm.tibl, control.pm.tibl, t='pm')

print(gg1)



```




```{r makeWEEK, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}


source.url <- c("./metrics/week_counts_df-.csv")

# get a lot of insect observations
week.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

pm.tibl <- week.tibl %>% 
  dplyr::filter(time == 'pm') 

# summary(pm.tibl)  # max = 15

gg <- ggplot() +
  
    geom_point(data=pm.tibl, 
                aes(y = p0, x = week, 
                colour = 4, fill = "green")
                ) +
    stat_summary(fun = mean, geom="line", size=3) + 
    stat_summary(fun.data = mean_se, geom = "errorbar") +

    scale_y_continuous(limits=c(0, 15),
                       breaks = seq(min(0), max(15), by = 1) ) +
                       
    theme_bw()  +
    # turn off legend
    theme(legend.position="none") 
  
    print(gg)



```



```{r makeNGRAM, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}


source.url <- c("./metrics/transect-compare-.csv")

# get a lot of insect observations
ngram.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

# 
pm.tibl <- ngram.tibl %>% 
  dplyr::filter(time == 'pm') %>%
  dplyr::select(julian, time, NGRAM.cosine.similarity) 

am.tibl <- ngram.tibl %>% 
  dplyr::filter(time == 'am') %>%
  dplyr::select(julian, time, NGRAM.cosine.similarity) 

```

```{r mcmc, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}

# normalized poisson data
library(MCMCpack)

source.url <- c("./metrics/prob_control_df-pm_1to4_23to25-.csv")
control.pm.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

source.url <- c("./metrics/prob_oakMargin_df-pm_1to4_23to25-.csv")
oakMargin.pm.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))


# Define log-posterior
log_post <- function(params, counts, frequencies) {
  lambda <- params[1]
  if (lambda <= 0) return(-Inf)  # Ensure positivity
  
  # Weighted log-likelihood using normalized frequencies
  log_lik <- sum(frequencies * dpois(counts, lambda, log = TRUE))
  
  # Gamma(1,1) prior for lambda
  log_prior <- dgamma(lambda, shape = 1, rate = 1, log = TRUE)
  
  return(log_lik + log_prior)
}

#df <- control.pm.tibl
df <- oakMargin.pm.tibl

posterior <- MCMCmetrop1R(
  log_post, 
  theta.init = 1, 
  burnin = 3000,
  mcmc = 50000,
  thin = 10,
  tune = 0.5,
  counts = df$count,
  frequencies = df$probability
)

# Diagnostics and visualization
library(coda)
plot(posterior)
summary(posterior)

# In summary:
# `MCMCmetrop1R` is a general-purpose tool for MCMC sampling from any user-defined posterior,
# especially useful when your model or likelihood is nonstandard or when you need to 
# incorporate custom data structures like normalized frequencies
# Diagnostics and Output
# 	•	The result is a `coda` mcmc object: use `summary(posterior)`, `plot(posterior)`, 
#     and diagnostics like `raftery.diag(posterior)`
# Notes
#	•	Alternative Distributions: Replace `dpois` with `dnbinom` (negative binomial) 
#   for overdispersed counts.
#	•	Priors: Adjust the gamma hyperparameters if you have prior knowledge about .
#	•	Efficiency: Increase `mcmc`/`burnin` if convergence is slow.

# https://search.r-project.org/CRAN/refmans/MCMCpack/html/MCMCmetrop1R.html
# https://faculty.ucr.edu/~jflegal/203/mcmcpack_huiling.html#1
# https://github.com/cran/MCMCpack/blob/master/R/MCMCmetrop1R.R
# https://andrewdmartin.washu.edu/app/uploads/2019/01/Applied-Bayesian-Inference-in-R-using-MCMCpack-2cv9ct9.pdf
# 

```

```{r graphics.2, echo=FALSE, include=TRUE, results='asis', message=F, warning=F, out.width=c('33%', '33%', '33%'), fig.show='hold'}


gg <- ggplot() +

  geom_histogram(data=am.tibl, 
                aes( 
                    y = NGRAM.cosine.similarity),
                colour = 4, fill = "white", 
                 bins = 15) +
    stat_summary(fun = mean, geom="line", size=3) + 
    stat_summary(fun.data = mean_se, geom = "errorbar") +

    scale_y_continuous(limits=c(0, 1.1),
                       breaks = seq(min(0), max(1.1), by = .2) ) +
  
    geom_histogram(data=pm.tibl, 
                aes( 
                    y = NGRAM.cosine.similarity),
                colour = 4, fill = "green", 
                 bins = 15) +
    stat_summary(fun = mean, geom="line", size=3) + 
    stat_summary(fun.data = mean_se, geom = "errorbar") +

    scale_y_continuous(limits=c(0, 1.1),
                       breaks = seq(min(0), max(1.1), by = .2) ) +

  	labs(x = "julian", y ="NGRAM.cosine.similarity", 
 				  title = paste("NGRAM.cosine.similarity",
 				                sep=""),
 				  subtitle = paste("ngram", sep=""),
 				  ) +
    
    # set default color for each group (otherwise geom_text text labels are "red")
    # https://stackoverflow.com/questions/41541708/how-to-change-font-color-in-geom-text-in-ggplot2-in-r
    # << or >>
    # https://stackoverflow.com/questions/61209218/changing-of-color-for-geom-text-gives-completely-different-color-then-called-for
    scale_colour_manual(values=c("#000000")) +
    
    coord_flip() +
    theme_bw()  +
    # turn off legend
    theme(legend.position="none") +
  
    theme(axis.text.x=element_text(angle=45,hjust=1)) 
  
    print(gg)

	

```


```{r graphics.1, echo=FALSE, include=TRUE, results='asis', message=F, warning=F, out.width=c('33%', '33%', '33%'), fig.show='hold'}


gg <- ggplot() +
  
    geom_jitter(data=pm.tibl, 
                aes(x = as.character(julian), 
                    y = NGRAM.cosine.similarity),
                    color = "black", fill = "red", 
                    shape = 25, size = 3, 
                    position = position_nudge(x = -0.1) ) +
  
    geom_jitter(data=am.tibl, 
                aes(x = as.character(julian), 
                    y = NGRAM.cosine.similarity),
                    color = "black", fill = "green", 
                    shape = 21, size = 3, 
                    position = position_nudge(x = -0.1) ) +
    stat_summary(fun = mean, geom="line", size=3) + 
    stat_summary(fun.data = mean_se, geom = "errorbar") +

    scale_y_continuous(limits=c(0, 1.1),
                       breaks = seq(min(0), max(1.1), by = .2) ) +

  	labs(x = "julian", y ="NGRAM.cosine.similarity", 
 				  title = paste("NGRAM.cosine.similarity",
 				                sep=""),
 				  subtitle = paste("ngram", sep=""),
 				  ) +
    
    # set default color for each group (otherwise geom_text text labels are "red")
    # https://stackoverflow.com/questions/41541708/how-to-change-font-color-in-geom-text-in-ggplot2-in-r
    # << or >>
    # https://stackoverflow.com/questions/61209218/changing-of-color-for-geom-text-gives-completely-different-color-then-called-for
    scale_colour_manual(values=c("#000000")) +
    
    coord_flip() +
    theme_bw()  +
    # turn off legend
    theme(legend.position="none") +
  
    theme(axis.text.x=element_text(angle=45,hjust=1)) 
  
    print(gg)

	

```

```{r saveFile, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}
     
saveGGpng <- function(filename, subdir, gg) {
  
      wd <- getwd() 
      
      # Check if the subdirectory exists
      if (dir.exists(file.path(subdir))) {
      
        dirPath <- paste(wd, "/", subdir, sep="")
        fullPath <- paste(dirPath, "/", filename, sep="")
  
        if (file.exists(fullPath)) { file.remove(fullPath) }
  
        suppressMessages(ggsave(filename, plot = gg, device = NULL, path = dirPath,
         scale = 1, width = 8, height = NA, dpi = 300, limitsize = TRUE,
         units = "in") )
        
        print(paste( "saved ", fullPath, sep=" "))
        
      } else {
        
        print(paste("subdirectory ", subdir, " does not exist", sep=""))
        
      }
      
return()
      
}

# ==================================================================================

saveDFpng <- function(filename, subdir, df) {
  
  library(gridExtra)
  library(grid)

      wd <- getwd() 
      
      # Check if the subdirectory exists
      if (dir.exists(file.path(subdir))) {
      
        dirPath <- paste(wd, "/", subdir, sep="")
        fullPath <- paste(dirPath, "/", filename, sep="")
  
        if (file.exists(fullPath)) { file.remove(fullPath) }
        
            library(gridExtra)
            library(png)
            # Save the table as a PNG
            png(fullPath, units = "in", width = 8, height = 4, res = 72, pointsize = 10)
            grid.table(df, rows = NULL)
            dev.off()
        
            if (FALSE) {
              library(magick)
              # Read the PDF (first page by default)
              img <- image_read_pdf("input.pdf", density = 300)  # Higher density = better quality
              # Save as PNG
              image_write(img, path = "output.png", format = "png")
            }

            if (FALSE) {
              #suppressMessages(ggsave(filename, plot = gg, device = NULL, path = dirPath,
              # scale = 1, width = 8, height = NA, dpi = 300, limitsize = TRUE,
              # units = "in") )
              # Open a PDF device
              pdf(fullPath, width = 8, height = 4)  # adjust size as needed
              #
              # Create a table grob with smaller font size
              g <- tableGrob(head(df), 
                    theme = ttheme_default(core = list(fg_params = list(fontsize = 10)),
                                           colhead = list(fg_params = list(fontsize = 10)),
                                           rowhead = list(fg_params = list(fontsize = 10))))
              # Draw the table
              #grid.table(df)
              grid::grid.draw(g)
              # Close the PDF device
              dev.off()
              print(paste( "saved ", fullPath, sep=" "))
            }
        
      } else {
        
        print(paste("subdirectory ", subdir, " does not exist", sep=""))
        
      }
      
return()
      
}
    
    
```  

```{r graphics.1, echo=FALSE, include=TRUE, results='asis', message=F, warning=F, out.width=c('33%', '33%', '33%'), fig.show='hold'}

source.url <- c("./metrics/row_similarity.csv")

# get a lot of insect observations
rows.tibl <- dplyr::as_tibble(read.csv(source.url, header=TRUE, row.names=NULL))

# thrips
t1_t2.tibl <- rows.tibl %>% 
  dplyr::select(julian, time, t1_t2) 
t1_t2.tibl <- t1_t2.tibl %>% rename(ngram_similarity = t1_t2)

t2_t3.tibl <- rows.tibl %>% 
  dplyr::select(julian, time, t2_t3) 
t2_t3.tibl <- t2_t3.tibl %>% rename(ngram_similarity = t2_t3)

t1_t3.tibl <- rows.tibl %>% 
  dplyr::select(julian, time, t1_t3) 
t1_t3.tibl <- t1_t3.tibl %>% rename(ngram_similarity = t1_t3)

stacked_df <- bind_rows(t1_t2.tibl, t2_t3.tibl)

stacked_df <- bind_rows(stacked_df, t1_t3.tibl)

stacked_am.tibl <- stacked_df %>% dplyr::filter(time == 'am')
stacked_pm.tibl <- stacked_df %>% dplyr::filter(time == 'pm')

gg <- ggplot() +
  
    geom_boxplot(data=stacked_am.tibl, 
                aes(x = as.character(julian), 
                    y = ngram_similarity),
                    #color = "black", 
                    fill = "green", 
                    alpha = 0.2,
                    #shape = 21, size = 3, 
                    position = position_nudge(x = -0.2) ) +
  
    geom_boxplot(data=stacked_pm.tibl, 
                aes(x = as.character(julian), 
                    y = ngram_similarity),
                    #color = "white", 
                    fill = "blue", 
                    alpha = 0.6,
                    #shape = 21, size = 3, 
                    position = position_nudge(x = +0.2) ) +
  

    scale_y_continuous(limits=c(0, 1.1),
                       breaks = seq(min(0), max(1.1), by = .2) ) +

  	labs(x = "julian", y ="NGRAM.cosine.similarity", 
 				  title = paste("NGRAM.cosine.similarity",
 				                sep=""),
 				  subtitle = paste("ngram", sep=""),
 				  ) +
    
    # set default color for each group (otherwise geom_text text labels are "red")
    # https://stackoverflow.com/questions/41541708/how-to-change-font-color-in-geom-text-in-ggplot2-in-r
    # << or >>
    # https://stackoverflow.com/questions/61209218/changing-of-color-for-geom-text-gives-completely-different-color-then-called-for
    scale_colour_manual(values=c("#000000")) +
    
    # coord_flip() +
    theme_bw()  +
    # turn off legend
    theme(legend.position="none") +
  
    theme(axis.text.x=element_text(angle=45,hjust=1)) 
  
    print(gg)

	

```