---
title: "overhead"
output: html_document
date: "2023-02-20"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

# this code will use the stats::kmeans() algorithm to identify clusters appearing in 
# weekly crab spider counts.

# https://yihui.org/knitr/options/

# echo: (TRUE; logical or numeric) Whether to display the source code
# results: ('markup'; character) Controls how to display the text results.
# warning: (TRUE; logical) Whether to preserve warnings
# error: (TRUE; logical) Whether to preserve errors
# include: (TRUE; logical) Whether to include the chunk output in the output document.
# 

```


```{r bytheway}

# what is the rank of insect occurrence?
  
  skimr::skim(bugs.tibl)


```


```{r area_plots, echo=FALSE, include=TRUE, results="hide", message=F, warning=T }

library(ggplot2)
library(dplyr)
library(vegan)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/wilcoxon-anova.R')

longForm <- function(df, tr, time) {
      
       counts.test <- df %>% mutate(position = c(1,2,3,4,5,6,7,8,9,10) ) 
       
       df_long.test <- pivot_longer(counts.test,
        cols = c(-position),   # All columns 
        names_to = "week",           # New column for week names
        values_to = "counts"          # New column for values
      )
      
      df_long.test <- df_long.test %>%
        mutate(week = as.integer(sub("^X", "", week)))
       
      # Aggregate
      df_ave <- df_long.test %>%
        group_by(position) %>%
        summarise(count_ave = mean(counts), .groups = "drop")
      
       # Calculate proportion of non-zero counts for each position
      df_prop <- df_long.test %>%
        group_by(position) %>%
        summarise(
          n = n(),                     # Total observations per position (should be 10)
          k = sum(counts > 0),         # Number of non-zero counts
          p_hat = k / n                # Observed proportion of non-zero counts
        )
      
      # Use the exact binomial test (Clopper-Pearson) to compute 95% CIs for each position.
      # (robust for small sample sizes (like 10 observations per position).)
      # For each position, compute CI using binom.test()
      df_ci <- df_prop %>%
        rowwise() %>%
        mutate(
          lower = binom.test(k, n, conf.level = 0.95)$conf.int[1],
          upper = binom.test(k, n, conf.level = 0.95)$conf.int[2]
        ) %>%
        ungroup()
      
      # A tibble: 10 × 6
      #   position     n     k p_hat lower upper
      #      <dbl> <int> <int> <dbl> <dbl> <dbl>
      # 1        1    11     6 0.545 0.234 0.833
      # 2        2    11     6 0.545 0.234 0.833
      # 3        3    11     7 0.636 0.308 0.891
      # 4        4    11     9 0.818 0.482 0.977
      # 5        5    11     8 0.727 0.390 0.940
      # 6        6    11     6 0.545 0.234 0.833
      # 7        7    11     8 0.727 0.390 0.940
      # 8        8    11     8 0.727 0.390 0.940
      # 9        9    11     8 0.727 0.390 0.940
      #10       10    11     5 0.455 0.167 0.766
      
      # Interpretation: For a position with `p_hat = 0.545`, we are 95% confident the true probability of a non-zero count is between `0.234` and `0.833`
      # probability of non-zero count not possible to add with 0s in the existing axis
      # geom_errorbar(data = df_ci, aes(x = position, y = p_hat, ymin = lower, ymax = upper), width = 0.2) +



# make a table for typst to record the probability of non-zero for each position
print(df_ci)

    
    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2") 
    
    j.color <- "royalblue3"
    s.color <- "royalblue4"
      
    if (tr == 'control') {
      j.color <- "darkorange3"
      s.color <- "darkorange4"
    }
     
    gg <- ggplot() + 
      
      geom_jitter(data = df_long.test, aes(x=position, y=counts),  
                  fill = j.color, shape = 21, size=3, alpha=.4) +
      
      geom_smooth(data = df_ave, aes(x=position, y=count_ave), 
                  method = "loess", se = FALSE, color = s.color, linewidth = 1.2) +
      
      # probability of non-zero count
      #geom_errorbar(data = df_ci, aes(x = position, y = p_hat, 
      #                                ymin = lower, ymax = upper), width = 0.2) +
    
      expand_limits(x=c(1,10)) +
      scale_x_continuous(breaks = seq(min(1), max(10), by = 1)) +
      
      expand_limits(y=c(1,15)) +
      scale_y_continuous(breaks = seq(min(0), max(15), by = 1)) +
      
      labs(x="trap ID", 
          y="weekly counts", 
          caption = paste("transect: ",  tr, ", daytime: ", time, sep="") ) +
    
      theme_bw() +
      theme(legend.position="none") 
     
  return(gg)
  
}

# a matrix:  rows=position, columns=weeks 
 counts.test <- dplyr::as_tibble(read.csv(
   './metrics/counts.position.SNH.pm.csv', header=TRUE, row.names=NULL))
 
  time <- 'pm'
  tr <- 'SNH'
  gg <- longForm(df=counts.test, tr=tr, time=time)
 
  print(gg)
  
  setwd("/Users/rcphelps/code/groq")
  saveGGpng(filename = paste("f.counts.by.pos.", tr, '.', time, ".png", sep=""), 
            subdir = "png.output", gg = gg)
  
  # ==========================================================================

# a matrix:  rows=position, columns=weeks 
 counts.test <- dplyr::as_tibble(read.csv(
   './metrics/counts.position.control.pm.csv', header=TRUE, row.names=NULL))
 
  time <- 'pm'
  tr <- 'control'
  gg <- longForm(df=counts.test, tr=tr, time=time)
 
  print(gg)
  
  setwd("/Users/rcphelps/code/groq")
  saveGGpng(filename = paste("f.counts.by.pos.", tr, '.', time, ".png", sep=""), 
            subdir = "png.output", gg = gg)
  

```






```{r bray-curtis-contiguous, echo=FALSE, include=TRUE, results="hide", message=F, warning=T }

library(ggplot2)
library(dplyr)
library(vegan)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/wilcoxon-anova.R')


# To assign clusters to contiguous positions (e.g., adjacent geographic locations or ordered time points) in R, use constrained hierarchical clustering, which ensures clusters are formed only from connected/adjacent positions. The `constr.hclust` function from the `adespatial` package is designed for this purpose.

# Key Features of `constr.hclust`
#	•	Contiguity enforcement: Clusters merge only if they are connected by edges in your neighbor list.
#	•	Spatial/temporal constraints: Ideal for geographic regions, time series, or linear sequences.
#	•	Flexible linkage methods: Supports `average`, `single`, `complete`, etc.

# When to Use This Approach
#	•	Clustering geographic regions (e.g., counties, plots).
#	•	Analyzing time series with chronological constraints.
#	•	Grouping administrative units or transect data.


# Step 1: Install and Load Required Packages
library(adespatial)

spatialClusters <- function(df) {
    
    # Step 2: Define Contiguity (Adjacency) Between Positions
    # Create a neighbor list or edge list specifying which positions are adjacent. For example, if positions 1–10 are arranged in a line:
    # Edge list for linear contiguity (1-2, 2-3, ..., 9-10)
    edges <- matrix(c(1,2, 2,3, 3,4, 4,5, 5,6, 6,7, 7,8, 8,9, 9,10), ncol = 2, byrow = TRUE)
    
    # Step 3: Perform Constrained Clustering
    # Example data: counts for 10 positions (rows) across 12 weeks (columns)
    #counts <- matrix(sample(0:7, 120, replace = TRUE), nrow = 10)
    
    counts <- df[, c("X23", "X24", "X25", "X26", "X27",
                            "X28", "X29", "X30", "X31", "X32", "X34")]
    
    # Compute dissimilarity matrix (e.g., Bray-Curtis)
    library(vegan)
    d <- vegdist(counts, method = "bray")
    
    # Constrained hierarchical clustering
    hc_constrained <- constr.hclust(d, links = edges, method = "average")
    
    # Plot dendrogram with contiguity constraint
    plot(hc_constrained, main = "Contiguous Clustering Dendrogram")
    
    #Step 4: Cut the Tree into Contiguous Clusters
    # Cut into 3 contiguous clusters
    clusters <- cutree(hc_constrained, k = 3)
    
    # Result: Each cluster contains only adjacent positions
    df <- data.frame(Position = 1:10, Cluster = clusters)
    
# You are correct: the hierarchical clustering example you saw does not compute clusters for each week separately. Instead, it clusters positions based on their entire pattern across all 12 weeks—that is, each position is represented as a 12-dimensional vector (its counts over the 12 weeks), and clustering is performed in this 12-dimensional space. The result is a single cluster assignment per position, not per week.
#Why isn’t the result 12 columns of clusters?
#	•	Because the clustering is performed on the positions as rows (observations), with weeks #as columns (variables/features).
#	•	Each position gets one cluster assignment that summarizes its pattern across all weeks.
#	•	You do not get a cluster assignment for each position in each week; you get one cluster per position.
#Does the example only compute the clusters for the first week?
#	•	No, unless you specifically subset your data to just one week (i.e., a single column), the clustering uses all weeks.
#	•	If you want to cluster positions for a single week, you must extract that week’s data (a vector of 10 counts) and cluster that vector separately.
    
    return(df)
    
}

    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2") 
    
 counts.position.SNH.pm.tibl <- dplyr::as_tibble(read.csv(
   './metrics/counts.position.SNH.pm.csv', header=TRUE, row.names=NULL))

  clusters.SNH.pm.tibl <- as_tibble(spatialClusters(df=counts.position.SNH.pm.tibl))
  
  
  tr="SNH"
  time<-"pm"

  rects <- data.frame(
                  xmin = c(22, 22, 22),
                  xmax = c(34, 34, 34),
                  ymin = c(1, 3.5, 4.5),
                  ymax = c(3.5, 4.5, 10),
                fill = c("royalblue4", "royalblue3", "royalblue2")
              )

  gg.SNH <- ggplot() +
       
       geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax, fill = fill), alpha = 0.7) +

        expand_limits(y=c(1,10)) +
        scale_y_continuous(breaks = seq(min(1), max(10), by = 1)) +
        
        expand_limits(x=c(22,34)) +    # enlarge the range of the axis
        scale_x_continuous(breaks=seq(22,34,2)) +         # log, squart-root, reverse....
    
scale_fill_manual(values = rects$fill) +
        
        geom_hline(yintercept=3.5) +
        geom_hline(yintercept=4.5) +
        
        labs(x="week number", 
             y="trap position", 
             caption = paste("transect: ",  tr, ", daytime: ", time, sep="") ) +
    
        theme_bw() +
        
        # turn off legend
        guides(color = "none", fill = "none") +
        theme(legend.position="none") 
 
    print(gg.SNH)
    setwd("/Users/rcphelps/code/groq")
    saveGGpng(filename = paste("f.clusters.SNH.", time, ".png", sep=""), 
                    subdir = "png.output", gg = gg.SNH)
    
# ==============================================================================   
# ==============================================================================
    
counts.position.control.pm.tibl <- dplyr::as_tibble(read.csv(
   './metrics/counts.position.control.pm.csv', header=TRUE, row.names=NULL))

  clusters.control.pm.tibl <- as_tibble(spatialClusters(df=counts.position.control.pm.tibl))

  tr="control"
  time<-"pm"

  rects <- data.frame(
                  xmin = c(22, 22, 22),
                  xmax = c(34, 34, 34),
                  ymin = c(1, 2.5, 6.5),
                  ymax = c(2.5, 6.5, 10),
                  fill = c("darkorange4", "darkorange3", "darkorange2")
                )

  gg.control <- ggplot() +
       
       geom_rect(data = rects, aes(xmin = xmin, xmax = xmax, 
                                   ymin = ymin, ymax = ymax, 
                                   fill = fill), alpha = 0.7) +

        expand_limits(y=c(1,10)) +
        scale_y_continuous(breaks = seq(min(1), max(10), by = 1)) +
        
        expand_limits(x=c(22,34)) +    # enlarge the range of the axis
        scale_x_continuous(breaks=seq(22,34,2)) +         # log, squart-root, reverse....
    
        scale_fill_manual(values = rects$fill) +
        
        geom_hline(yintercept=2.5) +
        geom_hline(yintercept=6.5) +
        
        labs(x="week number", 
             y="trap position", 
             caption = paste("transect: ",  tr, ", daytime: ", time, sep="") ) +
    
        theme_bw() +
        
        # turn off legend
        guides(color = "none", fill = "none") +
        theme(legend.position="none") 
 
    print(gg.control)
    setwd("/Users/rcphelps/code/groq")
    saveGGpng(filename = paste("f.clusters.control.", time, ".png", sep=""), 
                    subdir = "png.output", gg = gg.control)

```



```{r bray-curtis-experimental, echo=FALSE, include=TRUE, results="hide", message=F, warning=T }


# count data from 10 spatial positions in a vineyard row; there are multiple sets of count 
# data for these rows. how to determine clusters of spatial positions based on counts 

# Simulate count data for 10 positions in 2 paired rows
#set.seed(123)
positions <- 1:10  # Positions along the row

# Create synthetic data (e.g., pest counts)

# rows of positions ; coulumns of weeks


library(ggplot2)
library(dplyr)
library(vegan)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/wilcoxon-anova.R') 

# Mann-Whitney U Test (Wilcoxon Rank Sum Test)
#Purpose: Compares two independent groups to assess whether their distributions (usually medians) differ.
#Typical Use Case: Comparing values between two unrelated samples, such as test scores between two different classes, or measurements from two different transects
#R function: `wilcox.test(x, y, paired = FALSE)`

#Mann-Whitney U is for independent samples.
#	•	Wilcoxon Signed Rank is for paired/dependent samples.
#In summary:
#	•	Use the Mann-Whitney U test when comparing two independent groups.
#	•	Use the Wilcoxon Signed Rank test when comparing two related (paired) groups.
#Both tests are non-parametric and do not require the assumption of normality, but choosing the correct one depends on whether your samples are independent or paired


 plotHclust <- function(df, tr, time) { 
   
   # convert the tibbl into a matrix of counts per week
   # count_matrix <- count_data[, c("Pest_A", "Pest_B", "Pest_C")]
   #
   
   df.matrix <- df[, c("X23", "X24", "X25", "X26", "X27",
                            "X28", "X29", "X30", "X31", "X32", "X34")]
   
    # Compute Bray-Curtis dissimilarity
    bc_dist <- vegdist(df.matrix, method = "bray")
    
    # Perform hierarchical clustering
    hc <- hclust(bc_dist, method = "average")
    
    # Cut tree into 3 clusters
    clusters <- cutree(hc, k = 3)
    # `cutree()` assigns each row to a cluster based on all variables in your data.
	  # •	To get cluster assignments for individual variables (columns), you would need 
    # to cluster each variable separately (but this is rarely meaningful—clustering is
    # typically done on observations, not variables).
   
    # Plot dendrogram
    plot(hc)
    rect.hclust(hc, k = 3, border = "red")
    
    # Attach cluster labels to original data
    df$cluster <- clusters
    
    df <- df %>% mutate(position = c(1,2,3,4,5,6,7,8,9,10) ) 

    # Rename all columns at once (order matters)
    df <- set_names(df, c("23", "24", "25", "26", "27",
                            "28", "29", "30", "31", "32", "34",
                            "cluster", "position"))
      

      # pivot the df to 'long' configuration
      #
      
      print(df) 
      
      df_long <- pivot_longer(df,
        cols = c(-position, -cluster),   # All columns except 'position'
        names_to = "week",           # New column for week names
        values_to = "counts"          # New column for values
      )
      
      df_long <- df_long %>% mutate(week = as.integer(week) )
      
      print(df_long)
      
      W23 <- ggplot(df_long, aes(x = position, y = week, fill = factor(cluster))) +
          
            geom_tile() +
            
            scale_fill_manual(values = c("royalblue", "darkorange", "green")) +
            labs(title = "Cluster Assignments by Vineyard Position")
          
      print(W23)
      
        
      group_colors <- c(
        "1" = "black",  # Coral
        "2" = "grey",  # Teal
        "3" = "white",   # Sky blue
        "4" = "red"
      )
      
     gg <- ggplot() +

        geom_point(data = df_long, aes(x= week, y=position, 
                  fill=factor(cluster)), shape = 21, size=5) +

        expand_limits(y=c(1,10)) +
        scale_y_continuous(breaks = seq(min(1), max(10), by = 1)) +
        
        expand_limits(x=c(22,34)) +    # enlarge the range of the axis
        scale_x_continuous(breaks=seq(22,34,2)) +         # log, squart-root, reverse....
    
        scale_fill_manual(values = group_colors) +
        
        geom_hline(yintercept=4.5) +
        geom_hline(yintercept=7.5) +
        
        coord_fixed(ratio=1) + # control the aspect ratio
        
        labs(x="week number", 
             y="trap position", 
             caption = paste("transect: ",  tr, ", daytime: ", time, sep="") ) +
    
        theme_bw() +
        
        # turn off legend
        guides(color = "none", fill = "none") +
        theme(legend.position="none") 
 

   	return(gg)


}
 

# ==============================================================================
# The key is that each row is an observation to be clustered (here, a position), 
# and columns are the features (here, the 12 weekly counts)
# ==============================================================================

    wilcoxon.1.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.SNH.pm.csv', header=TRUE, row.names=NULL))


gg.hclust <- plotHclust(df=wilcoxon.1.tibl, tr="control", time='pm')

print(gg.hclust)



```




```{r bray-curtis-original, echo=FALSE, include=TRUE, results="hide", message=F, warning=T }

# count data from 10 spatial positions in a vineyard row; there are multiple sets of count 
# data for these rows. how to determine clusters of spatial positions based on counts 

# Simulate count data for 10 positions in 2 paired rows
#set.seed(123)
positions <- 1:10  # Positions along the row

# Create synthetic data (e.g., pest counts)
count_data <- data.frame(
  Position = rep(positions, 3),  # 10 positions x 2 rows
  Row = rep(c("Row_A", "Row_B", "Row_C"), each = 10),
  Pest_A = c(rpois(10, lambda = 5), rpois(10, lambda = 5), rpois(10, lambda = 5)),  # Higher in Row_B
  Pest_C = c(rpois(10, lambda = 5), rpois(10, lambda = 5), rpois(10, lambda = 5)),   # Higher in Row_A
  Pest_B = c(rpois(10, lambda = 5), rpois(10, lambda = 5), rpois(10, lambda = 5))   # Higher in Row_A
)

# =======================================================
# the input to dist() is a matrix or df where
#
# Rows represent observations (cases, samples, objects, etc.).
# Columns represent variables (features, measurements, etc.).
#
# `dist()` computes pairwise distances between the rows of the input matrix 
# or data frame, using the specified distance metric (e.g., Euclidean, Manhattan, etc.)
# =======================================================

library(vegan)
# Reshape data into a matrix (rows = positions, columns = pests)
count_matrix <- count_data[, c("Pest_A", "Pest_B", "Pest_C")]

# =======================================================
# create a disssimilarity matrix
# =======================================================

# Compute Bray-Curtis dissimilarity
bc_dist <- vegdist(count_matrix, method = "bray")

# =======================================================
# specify how the cluster differences are calculated
# =======================================================

# Perform hierarchical clustering
hc <- hclust(bc_dist, method = "average")

# =======================================================
# extrack cluster memberships
# =======================================================

# Cut tree into 2 clusters
clusters <- cutree(hc, k = 3)

# Attach cluster labels to original data
count_data$Cluster <- clusters

# Plot dendrogram
plot(hc, labels = paste("Pos", count_data$Position, "-", count_data$Row))
rect.hclust(hc, k = 3, border = "red")

# Spatial plot of positions colored by cluster
library(ggplot2)
ggplot(count_data, aes(x = Position, y = Row, fill = factor(Cluster))) +
  geom_tile(color = "white") +
  scale_fill_manual(values = c("royalblue", "darkorange", "green")) +
  labs(title = "Cluster Assignments by Vineyard Position")


```


```{r bray-curtis-orig_2, echo=FALSE, include=TRUE, results="hide", message=F, warning=T }

data <- data.frame(
  Position = LETTERS[1:10],
  Week1 = c(15, 0, 8, 20, 5, 12, 3, 7, 10, 2),
  Week2 = c(20, 5, 12, 18, 8, 15, 6, 9, 14, 4)
)

# Preprocess
count_matrix <- as.matrix(data[, -1])


# Distance and clustering
d <- vegdist(count_matrix, method = "bray")
clust <- hclust(d, method = "average")
plot(clust)

clusters <- cutree(clust, k = 3)

# Attach cluster labels to original data
data$Cluster <- clusters

THE POINT IS THAT WE ARE COPARING ONE THING (W1) TO ANOTHER THING (W2)
BY COMPUTING A DISTANCE AND THEN ASSIGNING A 'CLUSTER'


```




```{r bug-wilcoxon, echo=FALSE, include=F, results='asis', message=F, warning=F}
library(ggplot2)
library(dplyr)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/wilcoxon-anova.R') 

# Mann-Whitney U Test (Wilcoxon Rank Sum Test)
#Purpose: Compares two independent groups to assess whether their distributions (usually medians) differ.
#Typical Use Case: Comparing values between two unrelated samples, such as test scores between two different classes, or measurements from two different transects
#R function: `wilcox.test(x, y, paired = FALSE)`

#Mann-Whitney U is for independent samples.
#	•	Wilcoxon Signed Rank is for paired/dependent samples.
#In summary:
#	•	Use the Mann-Whitney U test when comparing two independent groups.
#	•	Use the Wilcoxon Signed Rank test when comparing two related (paired) groups.
#Both tests are non-parametric and do not require the assumption of normality, but choosing the correct one depends on whether your samples are independent or paired


wilcoxon.output.tibl <- tibble(
  week = character(),
  am.W = numeric(), 
  am.p = numeric(), 
  pm.W = numeric(), 
  pm.p = numeric()
)

    wilcoxon.1.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.SNH.am.csv', header=TRUE, row.names=NULL))
    wilcoxon.1.tibl <- wilcoxon.1.tibl %>%
        mutate(transect = "SNH") %>%
        mutate(time = "am") 
    
    # # A tibble: 10 × 13
    #      X23   X24   X25   X26   X27   X28   X29   X30   X31   X32
    #    <int> <int> <int> <int> <int> <int> <int> <int> <int> <int>
    #  1     1     5     0     0     0     4     0     2     0     1
    #  2     3     4     2     1     1     1     0     0     1     0
    #  3     0     3     1     0     1     1     0     0     0     0
    #  4     0     4     2     2     0     1     1     0     0     0
    #  5     0     4     4     2     0     1     1     0     0     0
    #  6     0     4     0     1     1     0     0     1     0     0
    #  7     4    12     5     1     0     4     1     2     1     0
    #  8     0     6     2     1     0     2     1     0     0     0
    #  9     0     1     2     1     1     5     0     1     0     1
    # 10     1     4     4     2     1     0     2     1     2     0
    # # ℹ 3 more variables: X34 <int>, transect <chr>, time <chr>

    
    wilcoxon.2.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.control.am.csv', header=TRUE, row.names=NULL))
    wilcoxon.2.tibl <- wilcoxon.2.tibl %>%
        mutate(transect = "control") %>%
        mutate(time = "am")     
    
    wilcoxon.3.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.SNH.pm.csv', header=TRUE, row.names=NULL))
    wilcoxon.3.tibl <- wilcoxon.3.tibl %>%
        mutate(transect = "SNH") %>%
        mutate(time = "pm") 
    
    wilcoxon.4.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.control.pm.csv', header=TRUE, row.names=NULL))
    wilcoxon.4.tibl <- wilcoxon.4.tibl %>%
        mutate(transect = "control") %>%
        mutate(time = "pm")     
    
     #     X23   X24   X25   X26   X27   X28   X29   X30
     #   <int> <int> <int> <int> <int> <int> <int> <int>
     # 1    1     5     0     0     0     4     0     2
     #2     3     4     2     1     1     1     0     0
     #3     0     3     1     0     1     1     0     0
     #4     0     4     2     2     0     1     1     0
     #5     0     4     4     2     0     1     1     0
     #6     0     4     0     1     1     0     0     1
     #7     4    12     5     1     0     4     1     2
     #8     0     6     2     1     0     2     1     0
     #9     0     1     2     1     1     5     0     1
     #0     1     4     4     2     1     0     2     1
     ## ℹ 3 more variables: X31 <int>, X32 <int>, X34 <int>
    
    am.tibl <- bind_rows(wilcoxon.1.tibl, wilcoxon.2.tibl)
    pm.tibl <- bind_rows(wilcoxon.3.tibl, wilcoxon.4.tibl)
  
      
  for (i in c("X23", "X24", "X25", "X26", "X27", "X28", "X29", "X30", "X31", "X32", "X34")) {
  #for (i in c("X24")) {
    
    #result <- wilcox.test(weight ~ company, data = dat, conf.int = TRUE)
    #result$p.value
    #result$statistic    # "W"
    #result$conf.int   
    
    #model.am <- wilcox.test(X23 ~ transect, data = am.tibl)
    formula_string <- paste(i, "~", "transect")
    results.am <- wilcox.test(as.formula(formula_string), data = am.tibl, conf.int = TRUE)
    results.pm <- wilcox.test(as.formula(formula_string), data = pm.tibl, conf.int = TRUE)
    
    s.stat.am <- round(results.am$statistic, 2)
    s.p_val.am  <- round(results.am$p.value, 2)
    s.stat.pm <- round(results.pm$statistic, 2)
    s.p_val.pm  <- round(results.pm$p.value, 2)
    
    wilcoxon.output.tibl <-  wilcoxon.output.tibl %>%
        add_row(week = sub("^X", "", i),         # regular expression to remove leading 'X'
                am.W = s.stat.am,
                am.p = s.p_val.am,
                pm.W = s.stat.pm,
                pm.p = s.p_val.pm
                )
    
    #print(paste("F: ", s.f_stat.am, "  p: ", s.p_val.am, sep=""))
    
  }
    
  #print(wilcoxon.output.tibl)
  # > print(anova.output.tibl)
# A tibble: 11 × 5
#   week   am.W  am.p  pm.W  pm.p
#   <chr> <dbl> <dbl> <dbl> <dbl>
# 1 23     60.5  0.42  60.5  0.25
# 2 24     36.5  0.32  36.5  0.4 
# 3 25     35.5  0.27  35.5  0.3 
# 4 26     36.5  0.29  36.5  0.41
# 5 27     42.5  0.54  42.5  0.47
# 6 28     38.5  0.39  38.5  0.79
# 7 29     64.5  0.26  64.5  0.22
# 8 30     55    0.71  55    0.18
# 9 31     67.5  0.16  67.5  0.43
#10 32     60    0.37  60    0.47
#11 34     55    0.37  55    0.3 
#> 

  setwd("/Users/rcphelps/code/groq/")
  write_csv(wilcoxon.output.tibl, "./metrics/wilcox.mwu.wk.output.csv", append=FALSE)
  
  
  # -------------------- now for the week clusters ------------------------
  
  
  wilcoxon.output.clusters.tibl <- tibble(
  week = character(),
  pm.W = numeric(), 
  pm.p = numeric()
)
      
  # sum columns and form a new column
  pm.tibl <- pm.tibl %>%
              mutate(cl1 = rowSums(across(c("X23", "X24", "X25")))) %>%
              mutate(cl2 = rowSums(across(c("X26", "X27", "X28", "X29", "X30", "X31")))) %>%
              mutate(cl3 = rowSums(across(c("X32", "X34")))) 
                     
  
  for (i in c("cl1", "cl2", "cl3")) {
    
    formula_string <- paste(i, "~", "transect")
    results.pm <- wilcox.test(as.formula(formula_string), data = pm.tibl, conf.int = TRUE)
    
    s.stat.pm <- round(results.pm$statistic, 2)
    s.p_val.pm  <- round(results.pm$p.value, 2)
    
    wilcoxon.output.clusters.tibl <-  wilcoxon.output.clusters.tibl %>%
        add_row(week = i,        
                pm.W = s.stat.pm,
                pm.p = s.p_val.pm )
    
  }
    
  #print(wilcoxon.output.tibl)
  # > print(anova.output.tibl)

  setwd("/Users/rcphelps/code/groq/")
  write_csv(wilcoxon.output.clusters.tibl, "./metrics/wilcox.mwu.cluster.output.csv", append=FALSE)
  
  
  
    
  #======================= end Mann-Whitney U =============================
  #========================================================================
  #========================================================================
```


```{r bug-wilcoxonSRT, echo=F, include=TRUE, results='asis', message=F, warning=F}
#======================= begin Wilcoxon Signed Rank Test ================
#========================================================================
#========================================================================
  
#	Purpose: Compares two related (paired or matched) samples to assess whether 
# their median difference is zero.
#	Typical Use Case: Pre-test vs. post-test measurements on the same subjects, 
# or before-and-after measurements on the same plots.
# R function: `wilcox.test(x, y, paired = TRUE)`.

library(ggplot2)
library(dplyr)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/wilcoxon-anova.R') 
  

  #  ( './metrics/counts_week.csv' created by spider_lb.py week_compare_counts(df)  )
  wilcoxon.SRT.tibl <- dplyr::as_tibble(read.csv('./metrics/counts_week.csv', 
                                                   header=TRUE, row.names=NULL))
  
  wilcoxon.SRT.output.tibl <- tibble( transect = character(),
                                      time = character(), 
                                      week = character(), 
                                      p.value = numeric() )
  
  # # A tibble: 10 × 133
  #    oakMargin.pm.23.79 oakMargin.pm.23.81 oakMargin.pm.23.83
  #                 <int>              <int>              <int>
  #  1                  0                  1                  0
  #  2                  0                  0                  3
  #  3                  1                  0                  2
  #  4                  1                  0                  1
  #  5                  0                  3                  0
  #  6                  2                  2                  1
  #  7                  0                  0                  0
  #  8                  3                  0                  0
  #  9                  2                  1                  0
  # 10                  2                  1                  1
  # # ℹ 130 more variables: oakMargin.pm.24.80 <int>,
  # #   oakMargin.pm.24.82 <int>, oakMargin.pm.24.84 <int>,
  
  # ==============================================================================
  # get a list of column names from './metrics/counts_week.csv' (wilcoxon.SRT.tibl)
  # and build a temporary tibl that is used to filter to data for ggplot
  
  column_names <- names(wilcoxon.SRT.tibl)
  
  column_repo.tibl <- tibble(
        column.name = character(),
        transect = character(),
        time = character(),
        week = character(),
        row = character() )
  
  for (i in 1:length(column_names)) {
    text <- column_names[[i]]
    parts <- strsplit(text, "\\.")[[1]]
    column_repo.tibl <- add_row(column_repo.tibl, column.name = column_names[[i]], transect = parts[[1]],
                                 time = parts[[2]], week = parts[[3]], row = parts[[4]])
  }
  # # A tibble: 133 × 5
  #    column.name        transect  time  week  row  
  #    <chr>              <chr>     <chr> <chr> <chr>
  #  1 oakMargin.pm.23.79 oakMargin pm    23    79   
  #  2 oakMargin.pm.23.81 oakMargin pm    23    81   
  #  3 oakMargin.pm.23.83 oakMargin pm    23    83   
  #  4 oakMargin.pm.24.80 oakMargin pm    24    80   
  #  5 oakMargin.pm.24.82 oakMargin pm    24    82   
  #  6 oakMargin.pm.24.84 oakMargin pm    24    84   
  #  7 oakMargin.pm.25.81 oakMargin pm    25    81   
  #  8 oakMargin.pm.25.83 oakMargin pm    25    83   
  #  9 oakMargin.pm.25.85 oakMargin pm    25    85   
  # 10 oakMargin.pm.26.83 oakMargin pm    26    83   
  # # ℹ 123 more rows
  
  # ==============================================================================
  
  # find rows from the same transect / time / week for comparison
  
  for (tr in c("oakMargin", "control")) {
    
    for (daytime in c("am", "pm")) {
      
      for (wk in c("23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "34")) {
      #for (wk in c("24")) {
        
        same_week_columns.tibl <- column_repo.tibl %>%
          filter(transect == tr) %>%
          filter(time == daytime) %>%
          filter(week == wk) 
        
        # # A tibble: 3 × 5
        #   column.name        transect  time  week  row  
        #   <chr>              <chr>     <chr> <chr> <chr>
        # 1 oakMargin.am.24.80 oakMargin am    24    80   
        # 2 oakMargin.am.24.82 oakMargin am    24    82   
        # 3 oakMargin.am.24.84 oakMargin am    24    84   
        # > 
        
        # there should be no more than 3 columns (in wilcoxon.SRT.tibl)
        # which means we are looking for 3 rows (the column labels)
        # in column_repo.tibl
        # 
        
        if (nrow(same_week_columns.tibl) == 3) {
          
          # This gets the column as a vector, then takes the first element.
          column_name_1 <- same_week_columns.tibl$column.name[1]
          column_name_2 <- same_week_columns.tibl$column.name[2]
          column_name_3 <- same_week_columns.tibl$column.name[3]
    
          # now run wilcoxon SRT on the data from each column
          # returns an object of class `"htest"`
          
          results.1 <- wilcox.test(wilcoxon.SRT.tibl[[column_name_1]], 
                                    wilcoxon.SRT.tibl[[column_name_2]], paired = TRUE)
          results.2 <- wilcox.test(wilcoxon.SRT.tibl[[column_name_1]], 
                                    wilcoxon.SRT.tibl[[column_name_3]], paired = TRUE)
          results.3 <- wilcox.test(wilcoxon.SRT.tibl[[column_name_2]], 
                                    wilcoxon.SRT.tibl[[column_name_3]], paired = TRUE)
          
          wilcoxon.SRT.output.tibl <-  wilcoxon.SRT.output.tibl %>%
                add_row(transect = tr, time = daytime, week = wk, p.value = round(results.1$p.value, 2) )
          wilcoxon.SRT.output.tibl <-  wilcoxon.SRT.output.tibl %>%
                add_row(transect = tr, time = daytime, week = wk, p.value = round(results.2$p.value, 2) )
          wilcoxon.SRT.output.tibl <-  wilcoxon.SRT.output.tibl %>%
                add_row(transect = tr, time = daytime, week = wk, p.value = round(results.3$p.value, 2) )
          
        }
        
        if (nrow(same_week_columns.tibl) == 2) {
          
          column_name_1 <- same_week_columns.tibl[[1, column.name]]
          column_name_2 <- same_week_columns.tibl[[2, column.name]]
          
          # now run wilcoxon SRT on the data from each column
          # returns an object of class `"htest"`
          
          results.1 <- wilcox.test(wilcoxon.SRT.tibl[[column_name_1]], 
                                    wilcoxon.SRT.tibl[[column_name_2]], paired = TRUE)
          
          wilcoxon.SRT.output.tibl <-  wilcoxon.SRT.output.tibl %>%
                add_row(transect = tr, time = daytime, week = wk, p.value = round(results.1$p.value, 2) )
          
        }
        
        
      }
    }
  }
  
  setwd("/Users/rcphelps/code/groq/")
  write_csv(wilcoxon.SRT.output.tibl, "./metrics/wilcox.srt.output.csv", append=FALSE)
  
  
    
```



```{r wilcox-gg-SRT, echo=TRUE, include=TRUE, results='asis', message=F, warning=F}

  library(ggplot2)
  library(dplyr)
  library(tidyr)

  source('/Users/rcphelps/code/groq/bug-library.R') 
  
  setwd("/Users/rcphelps/code/groq")
  
  
  input_filename = "./metrics/wilcox.srt.output.csv"
  wilcoxon.SRT.gg.input.tibl <- dplyr::as_tibble(read.csv(input_filename, header=TRUE, row.names=NULL))
  
  # # A tibble: 129 × 4
  #    transect  time  week  p.value
  #    <chr>     <chr> <chr>   <dbl>
  #  1 oakMargin am    23       0.34
  #  2 oakMargin am    23       0.18
  #  3 oakMargin am    23       0.15
  #  4 oakMargin am    24       0.71
  #  5 oakMargin am    24       0.26
  #  6 oakMargin am    24       0.17
  #  7 oakMargin am    25       0.33
  #  8 oakMargin am    25       0.17
  #  9 oakMargin am    25       0.46
  # 10 oakMargin am    26       0.48
  # ℹ 119 more rows
  # ℹ Use `print(n = ...)` to see more rows
  
    color_list <- list("royalblue4", "royalblue3", "royalblue2", "darkorange4", "darkorange3", "darkorange2")
    # https://sape.inf.usi.ch/quick-reference/ggplot2/colour
  
    for (tr in c("oakMargin", "control")) {
      
      if (tr == "oakMargin") {
        tr.label = "SNH"
        fill.color = "royalblue3"
      } else {
        tr.label = "control"
        fill.color = "darkorange3"
      }
      
      for (daytime in c("am", "pm")) {
        
          gg.tibl <- wilcoxon.SRT.gg.input.tibl %>%
                dplyr::filter(transect == tr) %>%
                dplyr::filter(time == daytime) 
          gg.tibl <- tidyr::drop_na(gg.tibl)
            
          gg.box <- ggplot() +
          
              geom_boxplot(data = gg.tibl, aes(x = as.factor(week), y = p.value), fill=fill.color) +
              
              scale_y_continuous(limits=c(0, 1.1), breaks=seq(0, 1.1, 0.1) ) +
              
              theme_bw() +
              
              labs(y = "row pair p-values", x = paste("week"),
                   caption = paste("daily row counts compared\n", "transect: ", tr.label, " daytime: ", daytime, sep="" ))
              
          print(gg.box)  
          setwd("/Users/rcphelps/code/groq/")
          saveGGpng(filename = paste("f.row.triplet.box.", tr, ".", daytime, ".png", sep=""), 
                    subdir = "png.output", gg = gg.box)
  
      }
    }
    
            
  
```

    
```{r cluster-wilcoxonSRT, echo=F, include=TRUE, results='asis', message=F, warning=F}
#======================= begin Wilcoxon Signed Rank Test ================
#========================================================================
#========================================================================
  
#	Purpose: Compares two related (paired or matched) samples to assess whether 
# their median difference is zero.
#	Typical Use Case: Pre-test vs. post-test measurements on the same subjects, 
# or before-and-after measurements on the same plots.
# R function: `wilcox.test(x, y, paired = TRUE)`.

library(dplyr)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/wilcoxon-anova.R') 
  

  #  ( './metrics/counts_week.csv' created by spider_lb.py week_compare_counts(df)  )
  wilcoxon.SRT.tibl <- dplyr::as_tibble(read.csv('./metrics/cluster_counts_week.csv', 
                                                   header=TRUE, row.names=NULL))
  
# # A tibble: 3,720 × 6
#   transect    row time   week Thomisidae..crab.spider. position
#   <chr>     <int> <chr> <int>                    <int>    <int>
# 1 oakMargin    79 pm       23                        0        1
# 2 oakMargin    79 pm       23                        0        2
# 3 oakMargin    79 pm       23                        0        3
# 4 oakMargin    79 pm       23                        0        4
# 5 oakMargin    79 pm       23                        0        5
# 6 oakMargin    79 pm       23                        0        6
# 7 oakMargin    79 pm       23                        1        7
  
  
  cluster.output.tibl <- tibble( transect = character(),
                                      time = character(), 
                                      week = character(),
                                      statistic = numeric(),
                                      p.value = numeric() )
  
  cluster.a.tibl <- wilcoxon.SRT.tibl %>% 
                      filter(position %in% c(1, 2, 3))
  
  cluster.c.tibl <- wilcoxon.SRT.tibl %>% 
                      filter(position %in% c(8, 9, 10))
  
  for (tr in c("oakMargin", "control")) {
    
    for (daytime in c("pm")) {
    # for (daytime in c("am", "pm")) {
      
      for (wk in c("23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "34")) {
      #for (wk in c("24")) {
        
        a.tibl <- cluster.a.tibl %>%
                      filter(transect == tr) %>%
                     filter(time == daytime) %>%
                     filter(week == wk) 
          
         c.tibl <- cluster.c.tibl %>%
                    filter(transect == tr) %>%
                    filter(time == daytime) %>%
                    filter(week == wk)  
         
        result <- wilcox.test(a.tibl$Thomisidae..crab.spider., c.tibl$Thomisidae..crab.spider., paired = TRUE)
          
        cluster.output.tibl <-  cluster.output.tibl %>%
                add_row(transect = tr, time = daytime, week = wk, 
                        statistic = round(result$statistic, 2),
                        p.value = round(result$p.value, 2) )

      }
    }
  }
  
  print(cluster.output.tibl)
  
setwd("/Users/rcphelps/code/groq/")
write_csv(cluster.output.tibl, "./metrics/cluster.output.csv", append=FALSE)
    
```





```{r bug-anova, echo=FALSE, include=TRUE, results='asis', message=F, warning=F}

library(ggplot2)
library(dplyr)

setwd("/Users/rcphelps/code/groq")
source('/Users/rcphelps/code/groq/bug-library.R') 
source('/Users/rcphelps/code/groq/anova.R') 

anova.output.tibl <- tibble(
  week = character(),
  am.f = numeric(), 
  am.p = numeric(), 
  pm.f = numeric(), 
  pm.p = numeric()
)

    anova.1.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.SNH.am.csv', header=TRUE, row.names=NULL))
    anova.1.tibl <- anova.1.tibl %>%
        mutate(transect = "SNH") %>%
        mutate(time = "am") 
    
    anova.2.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.control.am.csv', header=TRUE, row.names=NULL))
    anova.2.tibl <- anova.2.tibl %>%
        mutate(transect = "control") %>%
        mutate(time = "am")     
    
    anova.3.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.SNH.pm.csv', header=TRUE, row.names=NULL))
    anova.3.tibl <- anova.3.tibl %>%
        mutate(transect = "SNH") %>%
        mutate(time = "pm") 
    
    anova.4.tibl <- dplyr::as_tibble(read.csv('./metrics/counts.position.control.pm.csv', header=TRUE, row.names=NULL))
    anova.4.tibl <- anova.4.tibl %>%
        mutate(transect = "control") %>%
        mutate(time = "pm")     
    
    
     #     X23   X24   X25   X26   X27   X28   X29   X30
     #   <int> <int> <int> <int> <int> <int> <int> <int>
     # 1    1     5     0     0     0     4     0     2
     #2     3     4     2     1     1     1     0     0
     #3     0     3     1     0     1     1     0     0
     #4     0     4     2     2     0     1     1     0
     #5     0     4     4     2     0     1     1     0
     #6     0     4     0     1     1     0     0     1
     #7     4    12     5     1     0     4     1     2
     #8     0     6     2     1     0     2     1     0
     #9     0     1     2     1     1     5     0     1
     #0     1     4     4     2     1     0     2     1
     ## ℹ 3 more variables: X31 <int>, X32 <int>, X34 <int>
    
    am.tibl <- bind_rows(anova.1.tibl, anova.2.tibl)
    pm.tibl <- bind_rows(anova.3.tibl, anova.4.tibl)
  
      
  for (i in c("X23", "X24", "X25", "X26", "X27", "X28", "X29", "X30", "X31", "X32", "X34")) {
  #for (i in c("X24")) {
    
    #model.am <- aov(X23 ~ transect, data = am.tibl)
    formula_string <- paste(i, "~", "transect")
    model.am <- aov(as.formula(formula_string), data = am.tibl)
    model.pm <- aov(as.formula(formula_string), data = pm.tibl)
  
      #summary(model.pm)
      #            Df Sum Sq Mean Sq F value Pr(>F)
      #transect     1    3.2    3.20    1.14    0.3
      #Residuals   18   50.6    2.81               
      #> summary(model.am)
      #            Df Sum Sq Mean Sq F value Pr(>F)
      #transect     1   0.05    0.05    0.03   0.86
      #Residuals   18  26.90    1.49 
  
    results.am <- summary(model.am)
    results.pm <- summary(model.pm)
    
    s.f_stat.am <- round(results.am[[1]][["F value"]][1], 2)
    s.p_val.am  <- round(results.am[[1]][["Pr(>F)"]][1], 2)
    s.f_stat.pm <- round(results.pm[[1]][["F value"]][1], 2)
    s.p_val.pm  <- round(results.pm[[1]][["Pr(>F)"]][1], 2)
    
    anova.output.tibl <-  anova.output.tibl %>%
        add_row(week = sub("^X", "", i),         # regular expression to remove leading 'X'
                am.f = s.f_stat.am,
                am.p = s.p_val.am,
                pm.f = s.f_stat.pm,
                pm.p = s.p_val.pm
                )
    
    #print(paste("F: ", s.f_stat.am, "  p: ", s.p_val.am, sep=""))
    
  }
    
  print(anova.output.tibl)
  # > print(anova.output.tibl)
  # # A tibble: 11 × 5
  # #    week   am.f  am.p  pm.f  pm.p
  # #    <chr> <dbl> <dbl> <dbl> <dbl>
  # #  1 23     0.03  0.86  1.14  0.3 
  # #  2 24     0.59  0.45  0.68  0.42
  # #  3 25     1.8   0.2   1.36  0.26
  # #  4 26     0.2   0.66  1.19  0.29
  # #  5 27     0.13  0.72  0.95  0.34
  # #  6 28     1.45  0.24  0.03  0.87
  # #  7 29     1.69  0.21  1.14  0.3 
  # #  8 30     0.4   0.53  1.17  0.29
  # #  9 31     2.62  0.12  0.65  0.43
  # # 10 32     0.9   0.36  0.38  0.55
  # # 11 34     1     0.33  1.2   0.29
  # # > 

  setwd("/Users/rcphelps/code/groq/")
  write_csv(anova.output.tibl, "./metrics/anova.output.csv")
    
  #     TukeyHSD(one.way)
```




